
ğŸ›ï¸ AI Heritage Explorer
========================

**A conversational RAG assistant for art and history, powered by Llama 3.1 70b and Groq.**

<-- https://ai-heritage-explorer.streamlit.app/

_This application allows users to ask complex questions about cultural heritage. It retrieves factual context from Wikipedia and The Metropolitan Museum of Art, then uses a Large Language Model to synthesize that information into a detailed, conversational answer._

ğŸŒŸ Core Features
----------------

*   **Conversational Memory:**Â Remembers the context of your chat, allowing for natural follow-up questions.
    
*   **Hybrid Data Retrieval (RAG):**Â Fetches information from two distinct sources:
    
    *   **Unstructured Text:**Â Full Wikipedia articles are retrieved and chunked for deep context.
        
    *   **Structured Data:**Â The Met Museum's API is queried for specific artifact details, images, and links.
        
*   **Real-Time Vector Search:**Â Dynamically creates a FAISS vector index from the retrieved documents for each new topic.
    
*   **High-Speed Generation:**Â Uses theÂ **Llama 3.1 70b**Â model via theÂ **Groq API**Â for incredibly fast and high-quality text generation.
    
*   **Cited Sources:**Â Every response is backed by the data it was generated from, with links to the original articles and artifacts.
    

ğŸ› ï¸ Tech Stack
--------------

This project combines several modern AI and web technologies:

*   **Frontend:**Â [Streamlit](https://streamlit.io/)
    
*   **Backend & Orchestration:**Â [Python](https://www.python.org/),Â [LangChain](https://www.langchain.com/)
    
*   **LLM:**Â [Llama 3.1 8b](https://llama.meta.com/)Â (viaÂ [Groq API](https://groq.com/))
    
*   **Retrieval:**Â [Wikipedia API](https://pypi.org/project/wikipedia/),Â [Met Museum API](https://metmuseum.github.io/)
    
*   **Vector Store:**Â [FAISS](https://faiss.ai/)Â (in-memory)
    
*   **Embeddings:**Â all-MiniLM-L6-v2Â (viaÂ [HuggingFace](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2))
    
*   **Deployment:**Â [Streamlit Community Cloud](https://streamlit.io/cloud)
    

ğŸ”„ How It Works: The RAG Pipeline
---------------------------------

1.  **User Query:**Â The user asks a question (e.g., "What was special about Vermeer's paintings?").
    
2.  **Contextualize:**Â The app checks the chat history. If it's a follow-up, it rephrases the query (e.g., "What was special aboutÂ _Johannes Vermeer's_Â paintings?").
    
3.  **Retrieve:**
    
    *   Fetches the full Wikipedia article for "Johannes Vermeer".
        
    *   Queries the Met Museum API for "Vermeer" and gets artifact data.
        
4.  **Chunk & Embed:**Â The Wikipedia article is split into small chunks. All retrieved documents are converted into vectors (embeddings) and loaded into a FAISS vector store.
    
5.  **Search:**Â The app searches this vector store for the chunks most relevant to the user's query.
    
6.  **Augment:**Â The most relevant chunks (the "context") are combined with the user's query into a detailed prompt.
    
7.  **Generate:**Â This prompt is sent to the Llama 3.1 70b model, which synthesizes a single, comprehensive answer.
    
8.  **Stream:**Â The answer is streamed back to the user's screen, and the retrieved sources are displayed.
    

ğŸš€ Getting Started (Running Locally)
------------------------------------

You can run this project on your own machine by following these steps:

1.  git clone \[https://github.com/TaneshG13/ai-heritage-explorer.git\](https://github.com/TaneshG13/ai-heritage-explorer.git)cd ai-heritage-explorer
    
2.  \# On Windowspython -m venv venv.\\venv\\Scripts\\activate# On macOS/Linuxpython3 -m venv venvsource venv/bin/activate
    
3.  pip install -r requirements.txt
    
4.  **Set Up Your API Key:**
    
    *   Get a free API key fromÂ [Groq](https://groq.com/).
        
    *   Create a file at thisÂ _exact_Â path:Â .streamlit/secrets.toml
        
    *   GROQ\_API\_KEY = "gsk\_YourKeyGoesHere"
        
5.  streamlit run app.pyYour browser will automatically open to the app.
    

â˜ï¸ Deployment
-------------

This application is deployed and hosted live onÂ **Streamlit Community Cloud**. The deployment process is configured to:

*   Install all dependencies fromÂ requirements.txt.
    
*   Securely load theÂ GROQ\_API\_KEYÂ from the app's 'Secrets' settings.
